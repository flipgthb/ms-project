{
 "metadata": {
  "name": "",
  "signature": "sha256:598e40b13843f1894c80ea241cd3bc47f48b2c4ab0d10829ec64e3f3001cb04c"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import division, print_function\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import networkx as nx\n",
      "from scipy.special import erfc\n",
      "from collections import namedtuple\n",
      "import math\n",
      "import random\n",
      "import abc\n",
      "import time\n",
      "import datetime\n",
      "import itertools\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file MonteCarlo.py\n",
      "#!/usr/bin/env python\n",
      "# encoding: utf-8\n",
      "from __future__ import division, print_function\n",
      "import pandas as pd\n",
      "import math\n",
      "import random\n",
      "import time\n",
      "import datetime\n",
      "from Model import ModelMeta\n",
      "\n",
      "__all__ = [\"mcmc\", \"save_data\"]\n",
      "\n",
      "def mcmc(model, sweeps, save_state=False):\n",
      "    data = pd.DataFrame()\n",
      "    accepted = 0.0\n",
      "    \n",
      "    N = model.size\n",
      "    total_steps = sweeps*N\n",
      "    for t in xrange(total_steps):\n",
      "        proposition = model.propose()\n",
      "        if proposition is None:\n",
      "            continue\n",
      "        logp = model.logp(proposition)\n",
      "        acceptance = min(1, math.exp(logp))\n",
      "        rejection = random.random()\n",
      "        if rejection < acceptance:\n",
      "            model.state = proposition\n",
      "            accepted += 1\n",
      "            \n",
      "        if t % N == 0:\n",
      "            measured = model.measure()\n",
      "            measured[\"acceptance_ratio\"] = accepted / (t+1)\n",
      "            data = data.append(measured, ignore_index=True)\n",
      "    \n",
      "    p,names = zip(model.parameters.items())\n",
      "    stats = pd.Panel({p:data})\n",
      "    result = {\"statistics\":stats}\n",
      "    if save_state:\n",
      "        s = model.state\n",
      "        final_state = {k:pd.Panel({p:v}) for k,v in s.items()}\n",
      "        result.update(final_state)\n",
      "    for k,v in result.items():\n",
      "        v.items.set_names(names, inplace=True)\n",
      "    return result\n",
      "\n",
      "def save_data(path, data_tuple, time_stamp=True):\n",
      "    \n",
      "    ts = \"\"\n",
      "    if time_stamp:\n",
      "        lt = time.localtime()\n",
      "        ymd = lt.tm_year,lt.tm_mon,lt.tm_mday\n",
      "        date = datetime.date(*ymd)\n",
      "        ts = \"_\"+str(date)\n",
      "\n",
      "        \n",
      "    data = dict.fromkeys(data_tuple[0].keys())\n",
      "    for entry in data_tuple:\n",
      "        for k,v in entry.items():\n",
      "            try:\n",
      "                data[k].append(v)\n",
      "            except:\n",
      "                data[k] = [v]\n",
      "            \n",
      "    for file_name, data_list in data.items():\n",
      "        full_name = path + file_name + ts + \".csv\"\n",
      "        with open(full_name, \"w\") as file_:\n",
      "            panel = pd.concat(data_list)\n",
      "            panel.to_frame().to_csv(file_)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting MonteCarlo.py\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file Model.py\n",
      "#!/usr/bin/env python\n",
      "# encoding: utf-8\n",
      "import abc\n",
      "import math\n",
      "import random\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import networkx as nx\n",
      "from scipy.special import erfc\n",
      "\n",
      "__all__ = [\"ModelMeta\", \"MoralAgentModel\", \"MFPModel\"]\n",
      "\n",
      "class ModelMeta(object):\n",
      "    __metaclall__ = abc.ABCMeta\n",
      "    \n",
      "    @abc.abstractproperty\n",
      "    def size(self):\n",
      "        pass\n",
      "    \n",
      "    @abc.abstractproperty\n",
      "    def state(self):\n",
      "        pass\n",
      "    \n",
      "    @state.setter\n",
      "    def state(self, proposition):\n",
      "        pass\n",
      "    \n",
      "    @abc.abstractmethod\n",
      "    def logp(self, proposition=None):\n",
      "        pass\n",
      "    \n",
      "    @abc.abstractmethod\n",
      "    def measure(self):\n",
      "        pass\n",
      "    \n",
      "    @abc.abstractmethod\n",
      "    def propose(self):\n",
      "        pass\n",
      "    \n",
      "    @abc.abstractproperty\n",
      "    def parameters(self):\n",
      "        pass\n",
      "\n",
      "class MoralAgentModel(ModelMeta):\n",
      "    sqrt2 = math.sqrt(2)\n",
      "    sqrt2pi = math.sqrt(2*math.pi)    \n",
      "        \n",
      "    def __init__(self, beta, rho, epsilon, graph,\n",
      "                 agent_complexity, symmetry_breaking_direction=None,\n",
      "                 delta_state=0.1, delta_weight=0.5):\n",
      "        \n",
      "        self._sqrtD = math.sqrt(agent_complexity)\n",
      "        self._norm = self._sqrtD\n",
      "        self._gamma = math.sqrt(1-rho*rho)/rho\n",
      "        \n",
      "        self.beta = beta\n",
      "        self.rho = rho\n",
      "        self.epsilon = epsilon\n",
      "        self.parameter_names = (\"beta\",\"rho\",\"epsilon\")\n",
      "        self.network = graph.to_directed()\n",
      "        self.agent_complexity = agent_complexity\n",
      "        \n",
      "        self.delta_state = delta_state\n",
      "        self.delta_weight = delta_weight\n",
      "        \n",
      "        if symmetry_breaking_direction is None:\n",
      "            symmetry_breaking_direction = [1.0]*agent_complexity\n",
      "            \n",
      "        self.sbd = symmetry_breaking_direction\n",
      "        self.zeitgeist = np.asarray(self.sbd) * self._norm / np.linalg.norm(self.sbd)\n",
      "        self.D = agent_complexity\n",
      "        self.N = graph.order()\n",
      "        \n",
      "        for i in self.network.nodes_iter():\n",
      "            w = MoralAgentModel.sphere_rand(agent_complexity, self._norm)\n",
      "            self.network.node[i][\"vector\"] = w.copy()\n",
      "            self.network.node[i][\"opinion\"] = np.dot(w,self.zeitgeist) / self._sqrtD\n",
      "            \n",
      "        for i,j in self.network.edges_iter():\n",
      "            self.network[i][j][\"weight\"] = np.random.normal(loc=0.5, scale=0.05)    \n",
      "    @property\n",
      "    def size(self):\n",
      "        return self.N\n",
      "     \n",
      "    @property\n",
      "    def parameters(self):\n",
      "        b,r,e = self.beta, self.rho, self.epsilon\n",
      "        return dict(zip(self.parameter_names,(b,r,e)))\n",
      "        \n",
      "    @staticmethod\n",
      "    def sphere_rand(dim, norm, scale=1.0):\n",
      "        rv = np.random.multivariate_normal(np.zeros(dim), scale*np.eye(dim))\n",
      "        return rv * norm / np.linalg.norm(rv)\n",
      "\n",
      "        \n",
      "    @property\n",
      "    def state(self):\n",
      "        w = np.vstack(nx.get_node_attributes(self.network, \"vector\").values())\n",
      "        A = np.asarray(nx.attr_matrix(self.network, edge_attr=\"weight\")[0])\n",
      "        return {\"vectors\":w, \"adjacency\":A}\n",
      "    \n",
      "    @state.setter\n",
      "    def state(self, proposition):\n",
      "        agent = proposition[\"agent\"]\n",
      "        neig = proposition[\"neighbor\"]\n",
      "        self.network.node[agent[\"label\"]].update(agent[\"new_state\"])\n",
      "        self.network[agent[\"label\"]][neig[\"label\"]][\"weight\"] = proposition[\"link\"][\"new\"]\n",
      "        \n",
      "    def propose(self):\n",
      "        i = np.random.choice(self.N)\n",
      "        ei = self.network.edges(i, data=True)\n",
      "        ni,Ai = zip(*[(j,Aij[\"weight\"]) for _,j,Aij in ei])\n",
      "        pij = np.array(Ai)\n",
      "        pij /= pij.sum()\n",
      "        j = np.random.choice(ni, p=pij)\n",
      "        state_i = self.network.node[i]\n",
      "        opinion_i = state_i[\"opinion\"]\n",
      "        opinion_j = self.network.node[j][\"opinion\"]\n",
      "        x = np.sign(opinion_j * opinion_i)\n",
      "        Aij = Aij0 = self.network[i][j][\"weight\"]\n",
      "        Aij = Aij + Aij*(1-Aij)*x*self.delta_weight\n",
      "        w = state_i[\"vector\"] + MoralAgentModel.sphere_rand(self.D, self._norm,\n",
      "                                                            self.delta_state)\n",
      "        w *= self._norm / np.linalg.norm(w)\n",
      "        h = np.dot(w, self.zeitgeist) / self._sqrtD\n",
      "        new_state = {\"vector\":w, \"opinion\":h}\n",
      "        \n",
      "        proposition = {\n",
      "            \"agent\":{\"label\":i,\n",
      "                     \"state\":state_i,\n",
      "                     \"new_state\": new_state},\n",
      "            \"neighbor\":{\"label\":j,\n",
      "                        \"opinion\":opinion_j},\n",
      "            \"link\":{\"old\":Aij0, \"new\":Aij}\n",
      "        }\n",
      "        return proposition\n",
      "    \n",
      "    @staticmethod\n",
      "    def hamiltonian(hi, hj, Aij, Gamma, epsilon):\n",
      "        x = hi*np.sign(hj)/Gamma/MoralAgentModel.sqrt2\n",
      "        Jij = np.sign(Aij - 1/2)\n",
      "        A = Jij*MoralAgentModel.sqrt2pi\n",
      "        return -A*Gamma*np.log(epsilon + (1-2*epsilon)*erfc(-x)/2)\n",
      "    \n",
      "    def logp(self, proposition):\n",
      "        hi0 = proposition[\"agent\"][\"state\"][\"opinion\"]\n",
      "        hi = proposition[\"agent\"][\"new_state\"][\"opinion\"]\n",
      "        hj = proposition[\"neighbor\"][\"opinion\"]\n",
      "        Aij = proposition[\"link\"][\"new\"]\n",
      "        Aij0 = proposition[\"link\"][\"old\"]\n",
      "        E0 = MoralAgentModel.hamiltonian(hi0, hj, Aij0, self._gamma,\n",
      "                                         self.epsilon)\n",
      "        E = MoralAgentModel.hamiltonian(hi, hj, Aij, self._gamma,\n",
      "                                         self.epsilon)\n",
      "        BdE = self.beta * (E - E0)\n",
      "        return BdE\n",
      "        \n",
      "    def measure(self):\n",
      "        h = np.array(nx.get_node_attributes(self.network, \"opinion\").values())\n",
      "        m = h.mean()\n",
      "        v = h.var()\n",
      "        A = np.asarray(nx.attr_matrix(self.network, edge_attr=\"weight\")[0])\n",
      "        q = (A*h*h[:,None]).mean()\n",
      "        Enemies = np.where(A > 1/2, 0, 1)\n",
      "        n = Enemies.mean()\n",
      "        data = pd.Series([m,v,q,n],index=[\"m\",\"v\",\"q\",\"n\"])\n",
      "        return data\n",
      "    \n",
      "class MFModel(MoralAgentModel):\n",
      "    @staticmethod\n",
      "    def hamiltonian(hi, hj, Aij, rho, epsilon):\n",
      "        Jij = np.sign(Aij - 1/2)\n",
      "        v = -hi*hj + rho*abs(hi*hj)/2 - rho*abs(hi*hj+(1-2*epsilon))/2 \n",
      "        return Jij*v"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting Model.py\n"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import Model as mdl\n",
      "import MonteCarlo as mc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "g = nx.complete_graph(100)\n",
      "M = mdl.MoralAgentModel(10.0, 0.5, 0.25, g, 5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "prp = M.propose()\n",
      "LOGP = M.logp(prp)\n",
      "M.state = prp\n",
      "M.measure()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 33,
       "text": [
        "m    0.154363\n",
        "v    1.055504\n",
        "q    0.007063\n",
        "n    0.010000\n",
        "dtype: float64"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit x = mc.mcmc(M, 100, save_state=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1 loops, best of 3: 3.71 s per loop\n"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# tempo por agente por ponto do espa\u00e7o de fase\n",
      "t = 3.68 # [sec]\n",
      "N, sweeps = 100, 100\n",
      "total_agent_picks = N*sweeps\n",
      "ts = t/total_agent_picks # [sec/(agent*sweeps*phase_space_points*core)]\n",
      "total_phase_space = 5*5*5 # [beta*rho*epsilon]\n",
      "total_steps = 1000 * 100\n",
      "simulation_time = total_steps * ts * total_phase_space / 12 # [12 cores]\n",
      "simulation_time / 60 #/ 3600 #/ 24 # [days]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "6.388888888888888"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "r = mc.mcmc(M,100,save_state=True)\n",
      "r"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 36,
       "text": [
        "{'adjacency': <class 'pandas.core.panel.Panel'>\n",
        " Dimensions: 1 (items) x 100 (major_axis) x 100 (minor_axis)\n",
        " Items axis: (10.0, 0.5, 0.25) to (10.0, 0.5, 0.25)\n",
        " Major_axis axis: 0 to 99\n",
        " Minor_axis axis: 0 to 99, 'statistics': <class 'pandas.core.panel.Panel'>\n",
        " Dimensions: 1 (items) x 100 (major_axis) x 5 (minor_axis)\n",
        " Items axis: (10.0, 0.5, 0.25) to (10.0, 0.5, 0.25)\n",
        " Major_axis axis: 0 to 99\n",
        " Minor_axis axis: acceptance_ratio to v, 'vectors': <class 'pandas.core.panel.Panel'>\n",
        " Dimensions: 1 (items) x 100 (major_axis) x 5 (minor_axis)\n",
        " Items axis: (10.0, 0.5, 0.25) to (10.0, 0.5, 0.25)\n",
        " Major_axis axis: 0 to 99\n",
        " Minor_axis axis: 0 to 4}"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "M1 = mdl.MoralAgentModel(10.0, 0.5, 0.25, g, 5)\n",
      "x = mc.mcmc(M1, 100, save_state=True)\n",
      "M2 = mdl.MoralAgentModel(11.0, 0.5, 0.25, g, 5)\n",
      "y = mc.mcmc(M2,100, save_state=True)\n",
      "mc.save_data(\"/home/felippe/Desktop/\",(x,y))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    }
   ],
   "metadata": {}
  }
 ]
}